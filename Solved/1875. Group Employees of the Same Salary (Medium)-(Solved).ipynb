{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fadf709d-de3d-4bfc-b69f-3b489de68bef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4a1fef1-aa99-469c-b35f-9b3f3e81c9f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78daa073-80d8-4f7e-9cfa-10f6eb568909",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**1875. Group Employees of the Same Salary (Medium)**\n",
    "\n",
    "**Table: Employees**\n",
    "\n",
    "| Column Name | Type    |\n",
    "|-------------|---------|\n",
    "| employee_id | int     |\n",
    "| name        | varchar |\n",
    "| salary      | int     |\n",
    "\n",
    "employee_id is the column with unique values for this table.\n",
    "Each row of this table indicates the employee ID, employee name, and salary.\n",
    " \n",
    "A company wants to divide the employees into teams such that all the members on each team have the same salary. The teams should follow these criteria:\n",
    "- Each team should consist of at least two employees.\n",
    "- All the employees on a team should have the same salary.\n",
    "- All the employees of the same salary should be assigned to the same team.\n",
    "- If the salary of an employee is unique, we do not assign this employee to any team.\n",
    "- A team's ID is assigned based on the rank of the team's salary relative to the other teams' salaries, where the team with the lowest salary has team_id = 1. Note that the salaries for employees not on a team are not included in this ranking.\n",
    "\n",
    "**Write a solution to get the team_id of each employee that is in a team.**\n",
    "\n",
    "Return the result table ordered by team_id in ascending order. In case of a tie, order it by employee_id in ascending order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "**Input:** \n",
    "\n",
    "**Employees table:**\n",
    "\n",
    "| employee_id | name    | salary |\n",
    "|-------------|---------|--------|\n",
    "| 2           | Meir    | 3000   |\n",
    "| 3           | Michael | 3000   |\n",
    "| 7           | Addilyn | 7400   |\n",
    "| 8           | Juan    | 6100   |\n",
    "| 9           | Kannon  | 7400   |\n",
    "\n",
    "**Output:** \n",
    "| employee_id | name    | salary | team_id |\n",
    "|-------------|---------|--------|---------|\n",
    "| 2           | Meir    | 3000   | 1       |\n",
    "| 3           | Michael | 3000   | 1       |\n",
    "| 7           | Addilyn | 7400   | 2       |\n",
    "| 9           | Kannon  | 7400   | 2       |\n",
    "\n",
    "**Explanation:** \n",
    "- Meir (employee_id=2) and Michael (employee_id=3) are in the same team because they have the same salary of 3000.\n",
    "- Addilyn (employee_id=7) and Kannon (employee_id=9) are in the same team because they have the same salary of 7400.\n",
    "- Juan (employee_id=8) is not included in any team because their salary of 6100 is unique (i.e. no other employee has the same salary).\n",
    "- The team IDs are assigned as follows (based on salary ranking, lowest first):\n",
    "  - team_id=1: Meir and Michael, a salary of 3000\n",
    "  - team_id=2: Addilyn and Kannon, a salary of 7400\n",
    "- Juan's salary of 6100 is not included in the ranking because they are not on a team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b78bc27-26cd-4523-8646-7369baf68fcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n|employee_id|   name|salary|\n+-----------+-------+------+\n|          2|   Meir|  3000|\n|          3|Michael|  3000|\n|          7|Addilyn|  7400|\n|          8|   Juan|  6100|\n|          9| Kannon|  7400|\n+-----------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "employees_data_1875 = [\n",
    "    (2, \"Meir\", 3000),\n",
    "    (3, \"Michael\", 3000),\n",
    "    (7, \"Addilyn\", 7400),\n",
    "    (8, \"Juan\", 6100),\n",
    "    (9, \"Kannon\", 7400),\n",
    "]\n",
    "\n",
    "employees_columns_1875 = [\"employee_id\", \"name\", \"salary\"]\n",
    "employees_df_1875 = spark.createDataFrame(employees_data_1875, employees_columns_1875)\n",
    "employees_df_1875.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab95991e-6054-4263-9af5-75edc7ab9fb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "salary_counts_df_1875 = employees_df_1875\\\n",
    "                            .groupBy(\"salary\").agg(count(\"*\").alias(\"cnt\"))\\\n",
    "                                .filter(\"cnt >= 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f96ed471-0dbd-4911-91cc-a6c5411c15bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "windowSpec = Window.orderBy(\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b6cbc7-358b-45be-be12-67cd53536012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/expressions.py:1017: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "salary_with_team_df_1875 = salary_counts_df_1875\\\n",
    "                                .withColumn(\"team_id\", row_number().over(windowSpec))\\\n",
    "                                    .select(\"salary\", \"team_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6e093af-7adb-473a-a5a5-2c4e5b3634ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/expressions.py:1017: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------+-------+\n|salary|employee_id|   name|team_id|\n+------+-----------+-------+-------+\n|  3000|          2|   Meir|      1|\n|  3000|          3|Michael|      1|\n|  7400|          7|Addilyn|      2|\n|  7400|          9| Kannon|      2|\n+------+-----------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "employees_df_1875\\\n",
    "    .join(salary_with_team_df_1875, on=\"salary\", how=\"inner\")\\\n",
    "        .orderBy(\"team_id\", \"employee_id\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1875. Group Employees of the Same Salary (Medium)-(Solved)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
