{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "933f6fcf-3b7f-4e22-a9da-47224a7b1132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a044ca2-88c3-4a39-9ad3-12c7b6613c0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f16f61a0-1eda-4a08-9e41-e6bc4f90e5dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**196. Delete Duplicate Emails (Easy)**\n",
    "\n",
    "**Table: Person**\n",
    "\n",
    "| Column Name | Type    |\n",
    "|-------------|---------|\n",
    "| id          | int     |\n",
    "| email       | varchar |\n",
    "\n",
    "id is the primary key (column with unique values) for this table.\n",
    "Each row of this table contains an email. The emails will not contain uppercase letters.\n",
    " \n",
    "Write a solution to **delete** all duplicate emails, keeping only one unique email with the smallest id.\n",
    "\n",
    "For SQL users, please note that you are supposed to write a DELETE statement and not a SELECT one.\n",
    "\n",
    "For Pandas users, please note that you are supposed to modify Person in place.\n",
    "\n",
    "After running your script, the answer shown is the Person table. The driver will first compile and run your piece of code and then show the Person table. The final order of the Person table **does not matter**.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "**Input:**\n",
    "**Person table:**\n",
    "| id | email            |\n",
    "|----|------------------|\n",
    "| 1  | john@example.com |\n",
    "| 2  | bob@example.com  |\n",
    "| 3  | john@example.com |\n",
    "\n",
    "**Output:** \n",
    "| id | email            |\n",
    "|----|------------------|\n",
    "| 1  | john@example.com |\n",
    "| 2  | bob@example.com  |\n",
    "\n",
    "**Explanation:** john@example.com is repeated two times. We keep the row with the smallest Id = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99062cca-ba5f-4f53-a7b7-0a79518c0bf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "person_data_196 = [\n",
    "    (1, \"john@example.com\"),\n",
    "    (2, \"bob@example.com\"),\n",
    "    (3, \"john@example.com\")\n",
    "]\n",
    "\n",
    "# Create DataFrame for Person table\n",
    "person_columns_196 = [\"id\", \"email\"]\n",
    "person_df_196 = spark.createDataFrame(person_data_196, person_columns_196)\n",
    "person_df_196.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "196. Delete Duplicate Emails (Easy)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
