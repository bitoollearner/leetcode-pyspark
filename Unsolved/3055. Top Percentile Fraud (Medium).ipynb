{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d1791bd-9552-4116-90b2-daa678bbffb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2901fbc9-49db-4285-8b94-c460f34d4c4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "655120e7-6b25-417c-a08a-c6925feaa425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**3055.Â Top Percentile Fraud (Medium)**\n",
    "\n",
    "**Table: Fraud**\n",
    "\n",
    "| Column Name | Type    |\n",
    "|-------------|---------|\n",
    "| policy_id   | int     |\n",
    "| state       | varchar |\n",
    "| fraud_score | int     |\n",
    "\n",
    "policy_id is column of unique values for this table.\n",
    "This table contains policy id, state, and fraud score.\n",
    "The Leetcode Insurance Corp has developed an ML-driven predictive model to detect the likelihood of fraudulent claims. Consequently, they allocate their most seasoned claim adjusters to address the top 5% of claims flagged by this model.\n",
    "\n",
    "**Write a solution to find the top 5 percentile of claims from each state.**\n",
    "\n",
    "Return the result table ordered by state in ascending order, fraud_score in descending order, and policy_id in ascending order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "**Input:**\n",
    "**Fraud table:**\n",
    "| policy_id | state      | fraud_score | \n",
    "|-----------|------------|-------------|\n",
    "| 1         | California | 0.92        | \n",
    "| 2         | California | 0.68        |   \n",
    "| 3         | California | 0.17        | \n",
    "| 4         | New York   | 0.94        | \n",
    "| 5         | New York   | 0.81        | \n",
    "| 6         | New York   | 0.77        |  \n",
    "| 7         | Texas      | 0.98        |  \n",
    "| 8         | Texas      | 0.97        | \n",
    "| 9         | Texas      | 0.96        | \n",
    "| 10        | Florida    | 0.97        |  \n",
    "| 11        | Florida    | 0.98        | \n",
    "| 12        | Florida    | 0.78        | \n",
    "| 13        | Florida    | 0.88        | \n",
    "| 14        | Florida    | 0.66        | \n",
    "\n",
    "**Output:**\n",
    "| policy_id | state      | fraud_score |\n",
    "|-----------|------------|-------------|\n",
    "| 1         | California | 0.92        | \n",
    "| 11        | Florida    | 0.98        | \n",
    "| 4         | New York   | 0.94        | \n",
    "| 7         | Texas      | 0.98        |  \n",
    "\n",
    "**Explanation**\n",
    "- For the state of California, only policy ID 1, with a fraud score of 0.92, falls within the top 5 percentile for this state.\n",
    "- For the state of Florida, only policy ID 11, with a fraud score of 0.98, falls within the top 5 percentile for this state. \n",
    "- For the state of New York, only policy ID 4, with a fraud score of 0.94, falls within the top 5 percentile for this state. \n",
    "- For the state of Texas, only policy ID 7, with a fraud score of 0.98, falls within the top 5 percentile for this state. \n",
    "\n",
    "Output table is ordered by state in ascending order, fraud score in descending order, and policy ID in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2368434-0191-416c-aa1d-12cd44cf48e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fraud_data_3055 = [\n",
    "    (1, \"California\", 0.92),\n",
    "    (2, \"California\", 0.68),\n",
    "    (3, \"California\", 0.17),\n",
    "    (4, \"New York\", 0.94),\n",
    "    (5, \"New York\", 0.81),\n",
    "    (6, \"New York\", 0.77),\n",
    "    (7, \"Texas\", 0.98),\n",
    "    (8, \"Texas\", 0.97),\n",
    "    (9, \"Texas\", 0.96),\n",
    "    (10, \"Florida\", 0.97),\n",
    "    (11, \"Florida\", 0.98),\n",
    "    (12, \"Florida\", 0.78),\n",
    "    (13, \"Florida\", 0.88),\n",
    "    (14, \"Florida\", 0.66),\n",
    "]\n",
    "\n",
    "fraud_columns_3055 = [\"policy_id\", \"state\", \"fraud_score\"]\n",
    "fraud_df_3055 = spark.createDataFrame(fraud_data_3055, fraud_columns_3055)\n",
    "fraud_df_3055.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3055. Top Percentile Fraud (Medium)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
