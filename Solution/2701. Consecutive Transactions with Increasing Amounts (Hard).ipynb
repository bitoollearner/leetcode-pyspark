{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e9d71b1-88e9-445c-820a-b842e217a4e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6624c4d-8cb8-4ac4-8c72-81d1b4ecdb57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3788fe5-f4c9-420f-ad72-ec1a39310a2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**2701.Â Consecutive Transactions with Increasing Amounts (Hard)**\n",
    "\n",
    "**Table: Transactions**\n",
    "\n",
    "| Column Name      | Type |\n",
    "|------------------|------|\n",
    "| transaction_id   | int  |\n",
    "| customer_id      | int  |\n",
    "| transaction_date | date |\n",
    "| amount           | int  |\n",
    "\n",
    "transaction_id is the primary key of this table. \n",
    "Each row contains information about transactions that includes unique (customer_id, transaction_date) along with the corresponding customer_id and amount.  \n",
    "\n",
    "**Write an SQL query to find the customers who have made consecutive transactions with increasing amount for at least three consecutive days. Include the customer_id, start date of the consecutive transactions period and the end date of the consecutive transactions period. There can be multiple consecutive transactions by a customer.**\n",
    "\n",
    "Return the result table ordered by customer_id in ascending order.\n",
    "\n",
    "The query result format is in the following example.\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "**Input:** \n",
    "\n",
    "**Transactions table:**\n",
    "| transaction_id | customer_id | transaction_date | amount |\n",
    "|----------------|-------------|------------------|--------|\n",
    "| 1              | 101         | 2023-05-01       | 100    |\n",
    "| 2              | 101         | 2023-05-02       | 150    |\n",
    "| 3              | 101         | 2023-05-03       | 200    |\n",
    "| 4              | 102         | 2023-05-01       | 50     |\n",
    "| 5              | 102         | 2023-05-03       | 100    |\n",
    "| 6              | 102         | 2023-05-04       | 200    |\n",
    "| 7              | 105         | 2023-05-01       | 100    |\n",
    "| 8              | 105         | 2023-05-02       | 150    |\n",
    "| 9              | 105         | 2023-05-03       | 200    |\n",
    "| 10             | 105         | 2023-05-04       | 300    |\n",
    "| 11             | 105         | 2023-05-12       | 250    |\n",
    "| 12             | 105         | 2023-05-13       | 260    |\n",
    "| 13             | 105         | 2023-05-14       | 270    |\n",
    "\n",
    "**Output:** \n",
    "| customer_id | consecutive_start | consecutive_end | \n",
    "|-------------|-------------------|-----------------|\n",
    "| 101         |  2023-05-01       | 2023-05-03      | \n",
    "| 105         |  2023-05-01       | 2023-05-04      |\n",
    "| 105         |  2023-05-12       | 2023-05-14      | \n",
    "\n",
    "Explanation: \n",
    "- customer_id 101 has made consecutive transactions with increasing amounts from May 1st, 2023, to May 3rd, 2023\n",
    "- customer_id 102 does not have any consecutive transactions for at least 3 days. \n",
    "- customer_id 105 has two sets of consecutive transactions: from May 1st, 2023, to May 4th, 2023, and from May 12th, 2023, to May 14th, 2023. \n",
    "\n",
    "customer_id is sorted in ascending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "137536ea-9bec-4171-8dc2-4bf8b0d771b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions_data_2701 = [\n",
    "    (1, 101, \"2023-05-01\", 100),\n",
    "    (2, 101, \"2023-05-02\", 150),\n",
    "    (3, 101, \"2023-05-03\", 200),\n",
    "    (4, 102, \"2023-05-01\", 50),\n",
    "    (5, 102, \"2023-05-03\", 100),\n",
    "    (6, 102, \"2023-05-04\", 200),\n",
    "    (7, 105, \"2023-05-01\", 100),\n",
    "    (8, 105, \"2023-05-02\", 150),\n",
    "    (9, 105, \"2023-05-03\", 200),\n",
    "    (10, 105, \"2023-05-04\", 300),\n",
    "    (11, 105, \"2023-05-12\", 250),\n",
    "    (12, 105, \"2023-05-13\", 260),\n",
    "    (13, 105, \"2023-05-14\", 270),\n",
    "]\n",
    "\n",
    "transactions_columns_2701 = [\"transaction_id\", \"customer_id\", \"transaction_date\", \"amount\"]\n",
    "transactions_df_2701 = spark.createDataFrame(transactions_data_2701, transactions_columns_2701)\n",
    "transactions_df_2701.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2701. Consecutive Transactions with Increasing Amounts (Hard)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}